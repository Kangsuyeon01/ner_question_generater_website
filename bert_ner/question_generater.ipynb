{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 템플릿 생성하기\n",
    "\n",
    "### 문제 유형\n",
    "\n",
    "* 빈칸 유형\n",
    "* OX 유형\n",
    "* 오지선다형\n",
    "* 주관식\n",
    "\n",
    "서술형 문제는 의미역 구문 분석이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 23:23:19.536439: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5842f5b9888542f8861c14d474a05d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4aaa5fb95843e293c461ad3dd5bccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe5a681fa0d4df5a5aa41aec55e93c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 23:23:29.178638: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-30 23:23:30.592698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18829 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:19:00.0, compute capability: 8.6\n",
      "2023-01-30 23:23:30.593307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22300 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "2023-01-30 23:23:30.593732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22300 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:67:00.0, compute capability: 8.6\n",
      "2023-01-30 23:23:30.594107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22016 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from predict import ner_prediction, pos_process\n",
    "from transformers import  BertTokenizer, TFBertModel\n",
    "\n",
    "from konlpy.tag import Mecab # 형태소 단위로 나누기\n",
    "import kss # 문장단위로 나누기\n",
    "from pykospacing import Spacing# 띄어쓰기 교정하기\n",
    "from hanspell import spell_checker # 띄어쓰기 + 맞춤법 교정\n",
    "import random\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "\n",
    "silence_tensorflow() # 텐서플로우 경고 무시\n",
    "warnings.filterwarnings('ignore') # 경고 무시\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" # 3번 GPU 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Oh! You have konlpy.tag.Mecab in your environment. Kss will take this as a backend! :D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ktext = \"1873년 음력 11월 고종이 친정을 선포하면서 10년간 정권을 쥐고 있던 흥선대원군이 실각하고 명성황후를 필두로 한 여흥 민씨 정권이 들어서게 되었다. 이에 따라 자연스레 통상 개화론자들이 대두되면서 조선의 대외정책은 조금씩 변하기 시작했다. 이런 상황에서 1875년 음력 9월 20일 일본이 운요호 사건을 일으켜 조선에게 문호를 개방하라며 압박했다. 이에 대해 조선에서는 찬반 양론이 엇갈렸으나 결국 개항 찬성론자들의 입지가 강화되어 1876년 음력 2월 3일 일본과 강화도 조약을 체결하여 문호를 개방하였다. 이어서 고종은 일본에 파견한 수신사 김홍집이 귀국할 때 가져온 《사의조선책략》이라는 책을 읽고 깊은 인상을 받았으며, 그에 따라 조선 조정은 부국강병을 목표로 개화파 인물을 등용하여 개화 정책을 추진하였다. 뒤이어 일본에 신사유람단을, 청나라에 영선사를 파견하였다.조정에서는 개화정책을 전담하기 위한 기구인 통리기무아문을 두었고, 군사제도를 개혁하여 신식 군대인 별기군을 창설하였다. 1880년 음력 10월 11일 미국과 국교를 열었으며, 뒤이어 영국, 독일, 러시아, 프랑스 등 서구 열강들과 외교 관계를 맺었다. 그러나 이들과 맺은 조약들은 모두 치외 법권을 규정하고 국내 산업에 대한 보호 조처를 거의 취할 수 없게 규정된 불평등 조약들이었다.개화정책에 대하여 보수적인 유생층은 성리학적 전통질서를 지키고 외세를 배척하자는 위정척사 운동을 전개하였다. 이 운동은 외세의 침략을 막으려는 반외세 자주 운동이었지만 전통적인 사회체제를 그대로 유지하려고 하여 시대의 흐름에 뒤떨어진 한계를 지니고 있었다. 그러나 유생층 가운데서도 일부 혁신적 인사들은 유교 문화를 계승하면서 서양의 물질 문명을 부분적으로 수용하자는 동도서기론을 주장하며 개화운동에 참여하기도 하였다.\"\n",
    "ktext_list = kss.split_sentences(ktext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/suyeon/anaconda3/envs/py39/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import site; site.getsitepackages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 550.98it/s]\n",
      "2023-01-30 17:48:41.284991: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_load성공!!\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "kss_sentence = ner_prediction(ktext_list,max_seq_len=88, tokenizer=tokenizer, lang='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 문장을 올바른 띄어쓰기로 합쳐줌 (PyKoSacing)\n",
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_list = ['년','월','일','간','시','》','두',',','어'] # 태깅되어 빈칸이 되면 안되는 단어\n",
    "out_list = ['그러나','이에','이런','그럼에도','따라서','상황',] # 태깅 안되었지만 빠져야하는 단어 (제거되지 않은 불용어)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 빈칸 유형\n",
    "- 알고리즘: 개채명으로 인식된 단어에 빈칸 생성.\n",
    "  - 태그가 모두 '-'인 문장에는 문제가 생성되지 않음 \n",
    "  - '-'를 제외한 태그가 1개 이상 있어야 문제가 생성됨\n",
    "- 예시) 영조는 탕평책을 실시하여 왕권을 강화하였다.\n",
    "- 문제 출력: (______)는 탕평책을 실시하여 왕권을 강화하였다.\n",
    "- 정답: 영조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 833.03it/s]\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_load성공!!\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# 빈칸 유형 문제 생성\n",
    "PER_list = ['영조는 탕평책을 펼쳐 왕권을 강화하고 정치를 안정시켰다.','주몽은 부여를 떠나 졸본에 나라를 세웠다.']\n",
    "PER_sentence = ner_prediction(PER_list, max_seq_len=88, tokenizer=tokenizer, lang='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_emoty(sentences):\n",
    "    generated_question = []\n",
    "    for sentence in sentences:\n",
    "        question,answer = [],[]\n",
    "        for word in sentence:\n",
    "            if word[1] != '-':\n",
    "                if word[0] in in_list:\n",
    "                    question.append(word[0])\n",
    "                else:\n",
    "                    question.append(str('('+'_'*len(word[0])+')'))\n",
    "                    answer.append(word[0])\n",
    "            else:\n",
    "                if word[0] in out_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    question.append(word[0])\n",
    "        if answer: # 빈칸이 생성된 문장은 출력\n",
    "            generated_question.append([question,answer])\n",
    "    return generated_question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  ['(__)', '는', '(___)', '을', '펼쳐', '왕권', '을', '강화', '하', '고', '정치', '를', '안정', '시켰', '다', '.']\n",
      "Answer: ['영조', '탕평책']\n"
     ]
    }
   ],
   "source": [
    "empty = question_emoty(PER_sentence)\n",
    "print(\"Question: \",empty[0][0])\n",
    "print('Answer:',empty[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "kss_qa= question_emoty(kss_sentence)\n",
    "for i in range(len(kss_qa)):\n",
    "    print(\"Question\" ,i + 1, \": \" , spacing(\"\".join(kss_qa[i][0])))\n",
    "    print(\"Answer\" ,i + 1, \": \" , kss_qa[i][1])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OX 유형\n",
    "- 알고리즘: 해당 문장에 인식된 개채명 태그에서 같은 태그로 분류된 다른 단어 넣기\n",
    "  - 입력된 문장 내에서 같은 태그 내의 단어가 3가지 이상일 때 해당 문제를 제작\n",
    "  - OX 비율은 랜덤\n",
    "- 예시) 영조[PER] 는 탕평책을 펼쳤다. -> 세종대왕[PER]은 탕평책을 펼쳤다.\n",
    "- 문제 출력: 세종대왕은 탕평책을 펼쳤다. (O/X)\n",
    "- 정답: X, 영조\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_OX(sentences):\n",
    "    tag_dict = {}\n",
    "    Use_tag = {}\n",
    "    unUse_tag = ['NUM_B','NUM_I','DAT_I','DAT_B']\n",
    "    stop_word = ['일']\n",
    "\n",
    "    # 태그별로 단어를 리스트로 저장\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word[1] != '-':\n",
    "                if word[1] not in tag_dict:\n",
    "                    tag_dict[word[1]] = [word[0]]\n",
    "                else:\n",
    "\n",
    "                    tag_dict[word[1]].append(word[0])\n",
    "\n",
    "    # 문장에서 같은 태그의 단어가 3가지 이상인 태그 선별\n",
    "    for tag in tag_dict:\n",
    "        if tag not in unUse_tag:\n",
    "            if len(tag_dict[tag]) >= 3:\n",
    "                Use_tag[tag] = tag_dict[tag]\n",
    "    print(Use_tag)\n",
    "    # OX 비율은 randint 함수로 랜덤으로 비율 선정\n",
    "    ox_ratio = {}\n",
    "    for tag in Use_tag:\n",
    "        O_ratio = random.randint(0,len(Use_tag[tag]))\n",
    "        ox_ratio[tag] = O_ratio # 해당 태그에서 문제에 대한 답이 O일 비율은 O:X = O_ratio : len(Use_tag[tag]) - O_ratio\n",
    "    print(ox_ratio)\n",
    "\n",
    "    tagSort_sentence = {}\n",
    "    input_quesiton = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                # 태그별로 단어가 3개 이상인 태그의 문장 추출\n",
    "                # 중복을 방지하기 위해 이미 뽑은 문장은 제외함\n",
    "                if word[1] in Use_tag:\n",
    "                    if word[1] not in tagSort_sentence:\n",
    "                        tagSort_sentence[word[1]] = [sentence]\n",
    "                        break\n",
    "                    else:\n",
    "                        tagSort_sentence[word[1]].append(sentence)\n",
    "                        break\n",
    "\n",
    "    generated_question = []\n",
    "    # # OX 문제 생성\n",
    "    for tag in tagSort_sentence:\n",
    "        ox_rate = ox_ratio[tag] # OX 비율\n",
    "        o_idx = [] # 정답이 O인 문제의 인덱스\n",
    "\n",
    "        over_list = [] # 뽑을 수의 중복을 방지\n",
    "        for _ in range(ox_rate):\n",
    "            tmp_num = random.randint(0,ox_rate)\n",
    "            while tmp_num in over_list:\n",
    "                tmp_num = random.randint(0,ox_rate)\n",
    "            over_list.append(tmp_num)\n",
    "            o_idx.append(tmp_num)\n",
    "        \n",
    "        for i in range(len(tagSort_sentence[tag])):\n",
    "            question,answer = [], []\n",
    "            if i in o_idx: # 만약 정답이 O인 문제면 그냥 출제한다.\n",
    "                tmp_qusetion = tagSort_sentence[tag][i]\n",
    "                for word in tmp_qusetion:\n",
    "                    question.append(word[0])\n",
    "                answer.append('O')\n",
    "            else: # 정답이 X로 출력되어야 하는 문제는 같은 태그 내의 다른 단어로 바꿔서 출제한다.\n",
    "                tmp_qusetion = tagSort_sentence[tag][i]\n",
    "                answer_word = \"\"\n",
    "                for word in tmp_qusetion:\n",
    "                    if word[1] == tag: # 해당 단어가 바꿔야하는 태그라면\n",
    "                        word_set= list(set(Use_tag[tag]))\n",
    "                        word_set.pop(word_set.index(word[0]))\n",
    "                        i = random.randint(0,len(word_set)-1)\n",
    "                        change_word = word_set[i] # 사용할 태그 랜덤으로 선택\n",
    "                        question.append(change_word)\n",
    "                        answer_word = word[0]\n",
    "                    else:\n",
    "                        question.append(word[0])\n",
    "                        \n",
    "                answer.append('X')\n",
    "                answer.append(str(\"오답인 단어: \"+change_word))\n",
    "                answer.append(str('정답인 단어: '+answer_word ))\n",
    "                \n",
    "                \n",
    "            generated_question.append([question,answer])\n",
    "    return generated_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CVL_B': ['친정', '흥선대원군', '황후', '수신사', '사의조선책략', '부국강병', '신사', '통리기무아문', '위정척사'], 'LOC_B': ['조선', '일', '일본', '조선', '조선', '일', '일본', '일본', '조선', '일본', '청나라', '일', '미국', '영국', '독일', '러시아', '프랑스', '서양'], 'PER_B': ['문호', '고종', '김홍집']}\n",
      "{'CVL_B': 6, 'LOC_B': 4, 'PER_B': 2}\n",
      "Question 1 :  1873년 음력 11월 고종이 친정을 선포하면서 10년간 정권을 쥐고 있던 흥선대원군이 실각하고 명성황후를 필두로 한 여흥민씨 정권이 들어서게 되었다.\n",
      "Answer 1 :  ['O']\n",
      "\n",
      "Question 2 :  조정에서는 개화정책을 전담하기 위한 기구인 통리기무아문을 두었고 군사제도를 개혁하여 신식 군대인 별기군을 창설하였다.\n",
      "Answer 2 :  ['O']\n",
      "\n",
      "Question 3 :  개화정책에 보수적인 유생층은 성리학적 전통 질서를 지키고 외세를 배척하자는 수신사 운동을 전개하였다.\n",
      "Answer 3 :  ['X', '오답인 단어: 수신사', '정답인 단어: 위정척사']\n",
      "\n",
      "Question 4 :  통상 개화론자들이 대도 되면서 조선의 대외정책은 조금씩 변하기 시작했다.\n",
      "Answer 4 :  ['O']\n",
      "\n",
      "Question 5 :  1875년 음력 9월 20일 일본이 운요호사건을 일으켜 조선에게 문호를 개방하라며 압박했다.\n",
      "Answer 5 :  ['O']\n",
      "\n",
      "Question 6 :  조선에서는 찬반양론이 엇갈렸으나 개항 찬성론자들의 입지가 강화되어 1876년 음력 2월 3일 일본과 강화도조약을 체결하여 문호를 개방하였다.\n",
      "Answer 6 :  ['O']\n",
      "\n",
      "Question 7 :  일본에 신사유람단을 청나라에 영선사를 파견하였다.\n",
      "Answer 7 :  ['O']\n",
      "\n",
      "Question 8 :  1880년 음력 10월 11일 본 서양과 국교를 열었으며 일본 영국 영국 독일 서구 열강들과 외교관계를 맺었다.\n",
      "Answer 8 :  ['X', '오답인 단어: 독일', '정답인 단어: 프랑스']\n",
      "\n",
      "Question 9 :  유생층 가운데서도 일부 혁신적 인사들은 유교문화를 계승하면서 프랑스의 물질문명을 부분적으로 수용하자는 동도서기론을 주장하며 개화운동에 참여하기도 하였다.\n",
      "Answer 9 :  ['X', '오답인 단어: 프랑스', '정답인 단어: 서양']\n",
      "\n",
      "Question 10 :  고종은 일본에 파견한 수신사 김홍집이 귀국할 때 가져온 사의 조선책략이라는 책을 읽고 깊은 인상을 받았으며 그에 조선조 정은 부국강병을 목표로 개화파 인물을 등용하여 개화정책을 추진하였다.\n",
      "Answer 10 :  ['O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kss_qa= question_OX(kss_sentence)\n",
    "for i in range(len(kss_qa)):\n",
    "    print(\"Question\" ,i + 1, \": \" , spell_checker.check(\"\".join(kss_qa[i][0])).checked)\n",
    "    print(\"Answer\" ,i + 1, \": \" , kss_qa[i][1])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[EVET]가 일어난 시점(년도)는 언제인가?\n",
    "-> 답: NUM_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_qg(event_sentence):\n",
    "    for i in event_sentence:\n",
    "        stack = []\n",
    "        for token in i:\n",
    "            if \"EVT\" in token[1]:\n",
    "                print(\"Question: \" + token[0]+\"이 일어난 시점은 언제인가?\")\n",
    "                stack.append(\"EVT\")\n",
    "            if  \"EVT\" in stack and \"NUM\" in token[1]:\n",
    "                print(\"Answer: \" + token[0]) \n",
    "                del stack[stack.index('EVT')]\n",
    "            if \"DAT\" in token[1]:\n",
    "                # print(token) \n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1074.36it/s]\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_load성공!!\n"
     ]
    }
   ],
   "source": [
    "# _월_일은 무슨 날짜 인가?\n",
    "event_list = ['임진왜란은 1592년에 일어났다.']\n",
    "event_sentence = ner_prediction(event_list, max_seq_len=88, tokenizer=tokenizer, lang='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 임진왜란이 일어난 시점은 언제인가?\n",
      "Answer: 1592\n"
     ]
    }
   ],
   "source": [
    "event_qg(event_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(context):\n",
    "    ktext_list = kss.split_sentences(context)\n",
    "    kss_sentence = ner_prediction(ktext_list,max_seq_len=88, tokenizer=tokenizer, lang='ko')\n",
    "\n",
    "    kss_qa= question_emoty(kss_sentence)\n",
    "    empty_questions = []\n",
    "    empty_answers = []\n",
    "    for i in range(len(kss_qa)):\n",
    "        tmp = \"\".join(kss_qa[i][0])\n",
    "        # print(\"Question\" ,i + 1, \": \" , spell_checker.check(tmp).checked)\n",
    "        # print(\"Answer\" ,i + 1, \": \" , kss_qa[i][1])\n",
    "        # print()\n",
    "        empty_questions.append(spell_checker.check(tmp).checked)\n",
    "        empty_answers.append(kss_qa[i][1])\n",
    "\n",
    "    # print(\"=\"*30)\n",
    "    # print(\"OX 문제\")\n",
    "    # print(\"=\"*30)\n",
    "\n",
    "    kss_qa= question_OX(kss_sentence)\n",
    "    ox_questions = []\n",
    "    ox_answers = []\n",
    "    for i in range(len(kss_qa)):\n",
    "        tmp = \"\".join(kss_qa[i][0])\n",
    "        # print(\"Question\" ,i + 1, \": \" , spell_checker.check(tmp).checked)\n",
    "        # print(\"Answer\" ,i + 1, \": \" , kss_qa[i][1])\n",
    "        # print()\n",
    "        ox_questions.append(spell_checker.check(tmp).checked)\n",
    "        ox_answers.append(kss_qa[i][1])\n",
    "\n",
    "    return empty_questions,empty_answers, ox_questions, ox_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 780.58it/s]\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_load성공!!\n",
      "{'CVL_B': ['친정', '흥선대원군', '황후', '수신사', '사의조선책략', '부국강병', '신사', '통리기무아문', '위정척사'], 'LOC_B': ['조선', '일', '일본', '조선', '조선', '일', '일본', '일본', '조선', '일본', '청나라', '일', '미국', '영국', '독일', '러시아', '프랑스', '서양'], 'PER_B': ['문호', '고종', '김홍집']}\n",
      "{'CVL_B': 2, 'LOC_B': 5, 'PER_B': 2}\n"
     ]
    }
   ],
   "source": [
    "empty_questions,empty_answers, ox_questions, ox_answers = start(ktext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제를 json 파일로 변환 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1668733017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "unix_time = int(time())\n",
    "unix_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save QA as json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "QA_data = {\"empty_qa\": {\"questions\":empty_questions,\"answers\":empty_answers} ,\"ox_qa\":{\"questions\":ox_questions,\"answers\":ox_answers}}\n",
    "file_path = \"QA_data/\" + str(unix_time) + \".json\"\n",
    "with open(file_path, 'w') as outfile:\n",
    "    json.dump(QA_data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'empty_qa': {'questions': ['(____) 년 음력(__) 월 고종이(__)을 선포하면서(__) 연간 정권을 쥐고 있던(_____)이 실각하고 명성(__)를 필두로 한 여흥민씨 정권이 들어서게 되었다.',\n",
       "   '통상 개화론자들이 대도 되면서(__)의 대외정책은 조금씩 변하기 시작했다.',\n",
       "   '(____) 년 음력(_) 월(__) 일(__)이(___) 사건을 일으켜(__)에게 문호를 개방하라며 압박했다.',\n",
       "   '(__)에서는 찬반양론이 엇갈렸으나 개항 찬성론자들의 입지가 강화되어(____) 년 음력(_) 월(_) 일(__)과 강화도조약을 체결하여(__)를 개방하였다.',\n",
       "   '(__)은(__)에 파견한(___)(___)이 귀국할 때 가져온(______)이라는 책을 읽고 깊은 인상을 받았으며 그에(__) 조정은(____)을 목표로 개화파 인물을 등용하여 개화정책을 추진하였다.',\n",
       "   '(__)에(__) 유람단을(___)에 영선사를 파견하였다.',\n",
       "   '조정에서는 개화정책을 전담하기 위한 기구인(______)을 두었고 군사제도를 개혁하여 신식 군대인(___)을 창설하였다.',\n",
       "   '(____) 년 음력(__) 월(__) 일(__)과 국교를 열었으며(__)(__)(___)(___) 서구 열강들과 외교관계를 맺었다.',\n",
       "   '개화정책에 보수적인 유생층은 성리학적 전통 질서를 지키고 외세를 배척하자는(____) 운동을 전개하였다.',\n",
       "   '유생층 가운데서도 일부 혁신적 인사들은 유교문화를 계승하면서(__)의 물질문명을 부분적으로 수용하자는 동도서기론을 주장하며 개화운동에 참여하기도 하였다.'],\n",
       "  'answers': [['1873', '11', '친정', '10', '흥선대원군', '황후'],\n",
       "   ['조선'],\n",
       "   ['1875', '9', '20', '일본', '운요호', '조선'],\n",
       "   ['조선', '1876', '2', '3', '일본', '문호'],\n",
       "   ['고종', '일본', '수신사', '김홍집', '사의조선책략', '조선', '부국강병'],\n",
       "   ['일본', '신사', '청나라'],\n",
       "   ['통리기무아문', '별기군'],\n",
       "   ['1880', '10', '11', '미국', '영국', '독일', '러시아', '프랑스'],\n",
       "   ['위정척사'],\n",
       "   ['서양']]},\n",
       " 'ox_qa': {'questions': ['1873년 음력 11월 고종이 친정을 선포하면서 10년간 정권을 쥐고 있던 흥선대원군이 실각하고 명성황후를 필두로 한 여흥민씨 정권이 들어서게 되었다.',\n",
       "   '조정에서는 개화정책을 전담하기 위한 기구인 흥선대원군을 두었고 군사제도를 개혁하여 신식 군대인 별기군을 창설하였다.',\n",
       "   '개화정책에 보수적인 유생층은 성리학적 전통 질서를 지키고 외세를 배척하자는 위정척사운동을 전개하였다.',\n",
       "   '통상 개화론자들이 대도 되면서 영국의 대외정책은 조금씩 변하기 시작했다.',\n",
       "   '1875년 음력 9월 20일 일본이 운요호사건을 일으켜 조선에게 문호를 개방하라며 압박했다.',\n",
       "   '조선에서는 찬반양론이 엇갈렸으나 개항 찬성론자들의 입지가 강화되어 1876년 음력 2월 3일 일본과 강화도조약을 체결하여 문호를 개방하였다.',\n",
       "   '일본에 신사유람단을 청나라에 영선사를 파견하였다.',\n",
       "   '1880년 음력 10월 11일 미국과 국교를 열었으며 영국 독일 러시아 프랑스 서구 열강들과 외교관계를 맺었다.',\n",
       "   '유생층 가운데서도 일부 혁신적 인사들은 유교문화를 계승하면서 서양의 물질문명을 부분적으로 수용하자는 동도서기론을 주장하며 개화운동에 참여하기도 하였다.',\n",
       "   '고종은 일본에 파견한 수신사 김홍집이 귀국할 때 가져온 사의 조선책략이라는 책을 읽고 깊은 인상을 받았으며 그에 조선조 정은 부국강병을 목표로 개화파 인물을 등용하여 개화정책을 추진하였다.'],\n",
       "  'answers': [['O'],\n",
       "   ['X', '오답인 단어: 흥선대원군', '정답인 단어: 통리기무아문'],\n",
       "   ['O'],\n",
       "   ['X', '오답인 단어: 영국', '정답인 단어: 조선'],\n",
       "   ['O'],\n",
       "   ['O'],\n",
       "   ['O'],\n",
       "   ['O'],\n",
       "   ['O'],\n",
       "   ['O']]}}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0b1100'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(-12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b421ec79d7ca3e34b15f8471ad9207fade1051c5af676de55be8a37474d4423d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
